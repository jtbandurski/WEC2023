{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEC - preprocessing pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# VISUALIZATIONS\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#SCIPY\n",
    "from scipy import stats\n",
    "\n",
    "# STATSMODELS\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# SKLEARN\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    PowerTransformer,\n",
    "    RobustScaler,\n",
    "    MinMaxScaler\n",
    ")\n",
    "from sklearn.feature_selection import (\n",
    "    SequentialFeatureSelector,\n",
    "    SelectKBest,\n",
    "    f_classif\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    average_precision_score,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "\n",
    "# GRADIENT BOOSTING\n",
    "import xgboost as xgb\n",
    "import catboost as ctb\n",
    "\n",
    "# CATEGORY ENCODERS\n",
    "from category_encoders import (\n",
    "    CatBoostEncoder,\n",
    "    WOEEncoder,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder\n",
    ")\n",
    "\n",
    "# HYPERPARAMETER OPTIMIZATION\n",
    "import optuna as opt\n",
    "\n",
    "# EXPLAINABLE AI WITH SHAPLEY VALUES\n",
    "import shap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downcasting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dataframe(data):\n",
    "    # Source: https://www.kaggle.com/anshuls235/time-series-forecasting-eda-fe-modelling\n",
    "    df = data.copy()\n",
    "    \n",
    "    print(\"BEFORE downcast\")\n",
    "    print(df.info(memory_usage=\"deep\"))\n",
    "    print(\"=================\")\n",
    "    print(\"=================\", \"\\n\")\n",
    "\n",
    "    cols = df.dtypes.index.tolist()\n",
    "    types = df.dtypes.values.tolist()\n",
    "    for i, t in enumerate(types):\n",
    "        # Integer\n",
    "        if \"int\" in str(t):\n",
    "            # Check if minimum and maximum are in the limit of int8\n",
    "            if (\n",
    "                df[cols[i]].min() > np.iinfo(np.int8).min\n",
    "                and df[cols[i]].max() < np.iinfo(np.int8).max\n",
    "            ):\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int8)\n",
    "            # Check if minimum and maximum are in the limit of int16\n",
    "            elif (\n",
    "                df[cols[i]].min() > np.iinfo(np.int16).min\n",
    "                and df[cols[i]].max() < np.iinfo(np.int16).max\n",
    "            ):\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int16)\n",
    "            # Check if minimum and maximum are in the limit of int32\n",
    "            elif (\n",
    "                df[cols[i]].min() > np.iinfo(np.int32).min\n",
    "                and df[cols[i]].max() < np.iinfo(np.int32).max\n",
    "            ):\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int32)\n",
    "            # Choose int64\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.int64)\n",
    "        # Float\n",
    "        elif \"float\" in str(t):\n",
    "            if (\n",
    "                df[cols[i]].min() > np.finfo(np.float32).min\n",
    "                and df[cols[i]].max() < np.finfo(np.float32).max\n",
    "            ):\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float32)\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype(np.float64)\n",
    "        # Object\n",
    "        elif t == object:\n",
    "            if cols[i] == \"date\":\n",
    "                df[cols[i]] = pd.to_datetime(df[cols[i]], format=\"%Y-%m-%d\")\n",
    "            else:\n",
    "                df[cols[i]] = df[cols[i]].astype(\"category\")\n",
    "    print(\"AFTER downcast\")\n",
    "    print(df.info(memory_usage=\"deep\"))\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful pandas functions to remember:\n",
    "* dataset.describe()\n",
    "* dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_missings(df):\n",
    "    print(\"\\nMissing values in data:\")\n",
    "    print(df.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests for significance of the relationship and correlation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nominal - Nominal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis: no relation between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_test(df, feature1, feature2):   \n",
    "    contingency_tab = pd.crosstab(index = df[feature1], columns = df[feature2])\n",
    "    print(f\"\\nChi Square Test result between {feature1} and {feature2} variables.\")\n",
    "    print(stats.chi2_contingency(contingency_tab))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Continuous - binary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis: no significant correlation between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_biserial_corr(df, feature1, feature2):\n",
    "    print(f\"\\nPoint Biserial correlation between {feature1} and {feature2} variables:\")\n",
    "    print(stats.pointbiserialr(df[feature1], df[feature2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Continuous - continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_heatmap(df, method='spearman'):\n",
    "    corr = df.corr(method=method)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.set(font_scale=1.25)\n",
    "    sns.heatmap(\n",
    "        corr, linewidths=1.5, annot=True, square=True, fmt=\".2f\", annot_kws={\"size\": 10}\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Low variance indicates non-informative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_analysis(df, features_to_drop):\n",
    "    # source: https://www.kaggle.com/code/raphael2711/catboost-pipeline-nested-crossvalidation-optuna\n",
    "    Features = []\n",
    "    val=[]\n",
    "    var=[]\n",
    "    X=df.drop(columns=features_to_drop)\n",
    "\n",
    "    for column in X:\n",
    "        most_freq_value = np.round((X[column].value_counts(normalize = True).iloc[0])*100, 2)\n",
    "        variance=X[column].var()\n",
    "        Features.append(column)\n",
    "        val.append(most_freq_value)\n",
    "        var.append(variance)\n",
    "    count = pd.DataFrame(list(zip(Features, val,var)), columns =['Feature', 'Count%','Variance']).sort_values(ascending=False,by='Count%')\n",
    "    display(count.style.background_gradient(cmap = 'Reds', axis = 0,subset='Count%'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* variables highly correlated with other features should be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vif_analysis(dataset, features_to_drop):\n",
    "    # source: https://www.kaggle.com/code/raphael2711/catboost-pipeline-nested-crossvalidation-optuna\n",
    "    VIF = dataset.drop(columns=[features_to_drop])\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = VIF.columns\n",
    "    # calculating VIF for each feature \n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(VIF.values, i) for i in range(len(VIF.columns))]\n",
    "    vif_data=vif_data.sort_values(by='VIF',ascending=False)\n",
    "    vif_data.style.background_gradient(cmap = 'Reds', axis = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SelectKBest(f_classif) for ANOVA feature selection\n",
    "* Use it as a step in sklearn Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_hat, preds, labels):\n",
    "    conf_matrix = confusion_matrix(y_hat, preds, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGBoost"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
